# sodeeps_project2


## Hyper-Parameter

* Number of Hidden layer
* Number of Neuron in each layer
* Activation Function
  * Relu
  * Leaky Relu
  * Sigmoid
  * tanh
* Mini-Batch size
* Regularization
  * L2 Regularization
  * L1 Regularization
  * Drop-out
* Optimizer
  * Gradient Descent
  * Momentum(beta)
  * RMSprops(beta, epsilon)
  * Adam(beta1, beta2, epsilon)
* Ratio of train/validation/test dataset
